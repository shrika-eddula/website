<!DOCTYPE HTML>
<html>
<head>
    <title>Activation Aware BitDelta</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
</head>
<body class="is-preload">
    <!-- Header -->
    <div id="header">
        <div class="top">
            <!-- Logo -->
            <div id="logo">
                <span class="image avatar48"><img src="images/avatar.jpg" alt="" /></span>
                <h1 id="title">Shrika Eddula</h1>
                <p>Student at MIT</p>
            </div>
            <!-- Nav -->
            <nav id="nav">
                <ul>
                    <li><a href="index.html" id="top-link"><span class="icon solid fa-home">Intro</span></a></li>
                    <li><a href="#about" id="about-link"><span class="icon solid fa-user">About Me</span></a></li>
                    <li><a href="#portfolio" id="portfolio-link"><span class="icon solid fa-th">Portfolio</span></a></li>
                    <li><a href="#research" id="research-link"><span class="icon solid fa-flask">Research</span></a></li>
                    <li><a href="#contact" id="contact-link"><span class="icon solid fa-envelope">Contact</span></a></li>
                </ul>
            </nav>
        </div>
        <div class="bottom">
            <!-- Social Icons -->
            <ul class="icons">
                <li><a href="https://github.com/shrika-eddula" class="icon brands fa-github"><span class="label">Github</span></a></li>
                <li><a href="https://www.linkedin.com/in/shrika-eddula/" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
                <li><a href="mailto:shrika@mit.edu" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
                <li><a href="https://instagram.com/shrika_ed" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
            </ul>
        </div>
    </div>

    <!-- Project Content -->
    <div id="main">
        <section id="project" class="two">
            <div class="container">
                <!-- Left column for paper and presentation buttons -->
                <div class="left-column">
                    <a href="ActAwareBitDelta.pdf" class="button">Paper</a>
                    <a href="BitDeltaPoster.pdf" class="button">Poster</a>
                </div>
                <div class="right-column">
                    <header>
                        <h2>Activation Aware BitDelta</h2>
                        <p>A novel approach to neural network quantization that considers activation patterns for more efficient compression.</p>
                        <div class="skills">
                            <button class="skill-button">Neural Networks</button>
                            <button class="skill-button">Quantization</button>
                            <button class="skill-button">Model Compression</button>
                            <button class="skill-button">PyTorch</button>
                            <button class="skill-button">Deep Learning</button>
                        </div>
                    </header>
                    <div class="project-details">
                        <!-- Poster Image instead of Video -->
                        <div class="poster-image">
                            <img src="BitDeltaPoster.pdf" alt="BitDelta Poster" style="width: 100%; max-width: 800px;" />
                        </div>
                        <p>
                            Activation Aware BitDelta is a cutting-edge approach to neural network quantization that takes into account the activation patterns of neurons during the compression process. This method achieves superior compression rates while maintaining model accuracy by intelligently allocating bits based on the importance of different activation patterns in the network.
                        </p>
                        <p>
                            The project introduces a novel algorithm that analyzes neuron activation frequencies and their impact on model performance, using this information to guide the quantization process. This results in more efficient compression compared to traditional methods that treat all neurons equally.
                        </p>
                    </div>
                </div>
            </div>
        </section>
    </div>

    <!-- Footer -->
    <div id="footer">
        <ul class="copyright">
            <li>&copy; Shrika Eddula. All rights reserved.</li>
        </ul>
    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>
</body>
</html>
